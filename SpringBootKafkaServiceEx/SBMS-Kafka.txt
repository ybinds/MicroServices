			 Date : 10-01-2023
		    Spring Boot and Microservices
			7AM | Mr. Raghu | (ASHOK IT)
  ---------------------------------------------------------------------
https://kafka.apache.org/quickstart

			     Apache Kafka

*) It is a Open Source API used to connect multiple applications to
   send data (Message Queue)

*) Multi-Broker concept : it contains multiple brokers (Cluster)
   to send data to multiple consumers.

   [ActiveMQ - Single broker].

*) Scaling/Load Balancing can be done in Cluster.
*) Protocol independent (uses app protocol).

*) Kafka supports Pub/Sub Model only. No P2P. To send data to one consumer
   use only Pub/Sub.

*) Full Kafka S/w is called as EcoSystem. This system contains mainly
  3 parts. They are:

  1. Zoo Keeper : Controls entire system.
  2. Kafka Cluster : Group of Message Brokers(old version: min 3, new version: min 1)
  3. Topics : Memory that stores data in partitions


*) Data is exchanged in Serilized format (String/JSON/XML Data)
*) Producer and Consumer both are connected using TopicName.
*) By using KafkaTemplate<K,V> producer app will send data to Kafka.
   K = TopicName and V = Data
   and @KafkaListener(K) is used to read data at consumer app.


*) Topics is a memory that holds data in packets formats [dat blocks].
   Those are identified using index numbers starts from zero [offset]

*) MR : Messsage Replica creates cloned copies of actual data to send
   it to consumer.

*) ZooKeeper controls Eco-System like, create/manage topic, 
   allocate a broker to consumer, increase cluster size..etc

==========================================================================
Download : https://kafka.apache.org/downloads
Link: Scala 2.12  - kafka_2.12-2.8.1.tgz (asc, sha512)

Commands:
1. Start ZooKeeper
[Windows]
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

[Linux/MacOS]
.\bin\zookeeper-server-start.sh .\config\zookeeper.properties

*) Starts on Port : 2181

==============================================================
2. Start Kafka Server
[Windows]
.\bin\windows\kafka-server-start.bat .\config\server.properties

[Linux/MacOS]
.\bin\kafka-server-start.sh .\config\server.properties

*) Starts on port : 9092
================================================================
3. Create one topic

.\bin\windows\kafka-topics.bat --create --topic myabc --bootstrap-server localhost:9092

4. Start Producer Console

.\bin\windows\kafka-console-producer.bat --topic myabc --bootstrap-server localhost:9092

5. Start Consumer Console

.\bin\windows\kafka-console-consumer.bat --topic myabc --bootstrap-server localhost:9092
.\bin\windows\kafka-console-consumer.bat --topic myabc --from-beginning --bootstrap-server localhost:9092

*) Press ctrl+C to stop (execute in below order)
 Consumer > Producer > Kafka server > ZooKeeper

			 Date : 11-01-2023
		    Spring Boot and Microservices
			7AM | Mr. Raghu | (ASHOK IT)
  ---------------------------------------------------------------------
*) Kafka is Open Source and MQ S/w
*) Implemented by Apache
*) Uses LoadBalancer for Cluster (Multiple Message Broker)
*) Uses our application protocol
*) Kafka Supports only Pub/Sub Model (Topics).
   Even if we want to send message to one consumer use Topic only.
*) Kafka accepts only Serialized data for partitions.
*) Partitions contains index number [offset]

*) KafkaTemplate<K,V> is used at Producer application to send data
   to Kafka S/w

*) In case of non-Spring Boot application(Java app)
Ref this:
https://docs.spring.io/spring-kafka/reference/html/#with-java-configuration-no-spring-boot

*) Spring boot supports integration with kafka, we need to use JARs

<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

*) It gives auto-configuration for KafkaTemplate<K,V> and @KafkaListener
*) Both Producer and Consumer are connected using TopicName.

    @Bean
    public NewTopic topic() {
        return TopicBuilder.name("myabc")
                .partitions(10)
                .replicas(1)
                .build();
    }   

--cmd--
.\bin\windows\kafka-topics.bat 
  --create 
  --topic myabc 
  --partitions 10 
  --replicas 1
  --bootstrap-server localhost:9092


==================================================================


			 Date : 17-01-2023
		    Spring Boot and Microservices
			7AM | Mr. Raghu | (ASHOK IT)
  ---------------------------------------------------------------------
	Spring Boot + Apache Kafka Integration Example

*) We need to add Kafka API using Spring Boot in pom.xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

*) EcoSystem creates a connection with Producer application
 (by taking some properties) and supports sending data from producer
 to EcoSystem using KafkaTemplate<K,V> class.


*) If consumer also connected with EcoSystem, then one Message Broker
  is allocated to read data from TopicName using Message Replica(creates
   one copy of actual message)

  4 Consumers --> 1 Group --> Message Broker --> MR(4 copies)
  @KafkaListener takes topicName and groupId to read data from EcoSystem.

*) Im using RestController and MessageStore additionally to send data
   and view output.

======code=========================
Name : SpringBootKafkaServiceEx
Dep  : Lombok, Data JPA, MySQL, Web, Devtools, Spring For apache kafka


1. application.properties
# server port
server.port=8686

# Producer properties
spring.kafka.producer.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# Consumer properties
spring.kafka.consumer.bootstrap-servers=localhost:9092
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.group-id=abcd

# TopicName
my.topic.name=TEST-SAMPLE

# Database Properties
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/boot7am
spring.datasource.username=root
spring.datasource.password=root

# JPA Properties
spring.jpa.show-sql=true
spring.jpa.database-platform=org.hibernate.dialect.MySQL8Dialect
spring.jpa.hibernate.ddl-auto=create


2. Entity
package com.app.raghu.entity;

import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.GeneratedValue;
import javax.persistence.GenerationType;
import javax.persistence.Id;
import javax.persistence.Table;

import lombok.Data;

@Data
@Entity
@Table(name="stocktab")
public class StockInfo {
	
	@Id
	@GeneratedValue(strategy = GenerationType.IDENTITY)
	@Column(name="sid")
	private Integer stkId;
	
	@Column(name="scode")
	private String stkCode;
	
	@Column(name="scost")
	private Double stkCost;
	
}

3. Repository
package com.app.raghu.repo;

import org.springframework.data.jpa.repository.JpaRepository;

import com.app.raghu.entity.StockInfo;

public interface StockInfoRepository extends JpaRepository<StockInfo, Integer> {

}

4. JSONUTIL
package com.app.raghu.util;

import com.app.raghu.entity.StockInfo;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

public class JsonUtil {

	public static StockInfo convertToObj(String message) {
		try {
			return new ObjectMapper().readValue(message, StockInfo.class);
		} catch (JsonProcessingException e) {
			e.printStackTrace();
		}
		return null;
	}

	public static String convertToString(StockInfo si) {
		try {
			return new ObjectMapper().writeValueAsString(si);
		} catch (JsonProcessingException e) {
			e.printStackTrace();
		}
		return null;
	}

}

5. MessageStore
package com.app.raghu.db;

import java.util.List;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import com.app.raghu.entity.StockInfo;
import com.app.raghu.repo.StockInfoRepository;
import com.app.raghu.util.JsonUtil;

@Component
public class MessageStore {
	
	@Autowired
	private StockInfoRepository repo;

	public void add(String message) {
		//JSON TO Object
		StockInfo si = JsonUtil.convertToObj(message);
		repo.save(si);
	}

	public List<StockInfo> getAll() {
		return repo.findAll();
	}

}

6. Consumer Service
package com.app.raghu.service;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import com.app.raghu.db.MessageStore;

import lombok.extern.slf4j.Slf4j;

@Component
@Slf4j
public class ConsumerService {
	
	@Autowired
	private MessageStore store;

	@KafkaListener(topics = "${my.topic.name}",groupId = "abcd")
	public void readMessage(String message) {
		log.info("MESSAGE AT CONSUMER : {}", message);
		store.add(message);
	}
}


7. Producer service
package com.app.raghu.service;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import lombok.extern.slf4j.Slf4j;

@Component
@Slf4j
public class ProducerService {

	@Autowired
	private KafkaTemplate<String, String> template;
	
	@Value("${my.topic.name}")
	private String topicName;
	
	public void sendMessage(String message) {
		log.info("MESSAGE IS AT PRODUCER SERVICE");
		template.send(topicName, message);
	}
}


8. RestController
package com.app.raghu.rest;

import java.util.List;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import com.app.raghu.db.MessageStore;
import com.app.raghu.entity.StockInfo;
import com.app.raghu.service.ProducerService;
import com.app.raghu.util.JsonUtil;

@RestController
@RequestMapping("/api/v1/kafka")
public class StockRestController {
	
	@Autowired
	private ProducerService service;
	
	@Autowired
	private MessageStore store;

	//send?code=__&cost=__
	@GetMapping("/send")
	public String readMessage(
			@RequestParam String code,
			@RequestParam Double cost
			) 
	{
		//create Entity class object
		StockInfo si = new StockInfo();
		si.setStkCode(code);
		si.setStkCost(cost);
		
		//convert to JSON
		String message = JsonUtil.convertToString(si);
		
		//call producer service
		service.sendMessage(message);
		
		return "SENT";
	}
	
	@GetMapping("/all")
	public List<StockInfo> fetchAll() {
		return store.getAll();
	}
	
	
}



=======execution order==========================
1. run zookeeper
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

2. run kafka server
.\bin\windows\kafka-server-start.bat .\config\server.properties


3. run your app

4. enter urls

http://localhost:8686/api/v1/kafka/send?code=A&cost=50.0
http://localhost:8686/api/v1/kafka/all


			 Date : 18-01-2023
		    Spring Boot and Microservices
			7AM | Mr. Raghu | (ASHOK IT)
  ---------------------------------------------------------------------
*) JACKSON API (open source Java API)
 This API is used to convert
	1. Java Object to JSON 
	2. JSON to Java Object

(C) ObjectMapper 
	(M) write__   Obj->JSON
	(M) read__    JSON->OBJ

==Example code==========
*) if we create any Spring boot application with Web Dependeny
  then by default JACKSON API is also added.


1. Model / Entity
package com.app.raghu.entity;

import lombok.Data;
@Data
public class StockInfo {
	private Integer stkId;
	private String stkCode;
	private Double stkCost;
	
}

2. Test class
package com.app.raghu;

import com.app.raghu.entity.StockInfo;
import com.fasterxml.jackson.databind.ObjectMapper;

public class Test {
	
	//JSON to Object
	public static void main(String[] args) {
		String json ="{\"stkId\":101,\"stkCode\":\"A\",\"stkCost\":200.0}";
		
		try {
			ObjectMapper om = new ObjectMapper();
			StockInfo si = om.readValue(json, StockInfo.class);
			System.out.println(si);
		} catch (Exception e) {
			e.printStackTrace();
		}
	}

	//Object to JSON
	public static void main1(String[] args) {
		StockInfo si = new StockInfo();
		si.setStkCode("A");
		si.setStkCost(200.0);
		si.setStkId(101);
		
		try {
			ObjectMapper om = new ObjectMapper();
			String s = om.writeValueAsString(si);
			System.out.println(s);
		} catch (Exception e) {
			e.printStackTrace();
		}
	}
}
======================================================================
Topic: Apache Kafka supports only Topics to send data even for 1 to 1 also.
 No P2P -- Queue concept in kafka. Everything is Pub/Sub -- Topic 

@Bean
public NewTopic topic() {
       return TopicBuilder.name("topic1")
               .partitions(10) //based on message sizes
               .replicas(1) // no.of consumers
               .build();
}
//default values are : partitions=1 , replicas =1 
(or) KafkaTemplate creates given topic name on the fly (at runtime)

*)Group : Logical unit of a multiple consumers which are using same topicName
 In this case MessageBroker informs MessageReplica to create Cloned Copies

 ex: group=abc, consumers=5 , topicName=TEST-A
  MessageBroker-5 is allocated, MR-5 copies of actual message from TEST-A

======================================================================
*) When ever KafkaTemplate calls send method then Kafka API creates one object
  ProducerRecord (C)

Internal code: Data --> Serialized
ProducerRecord<K, V> producerRecord = new ProducerRecord<>(topic, data);

*) @KafkListener that reads data from given topicName into ConsumerRecord(C)

//Data -> Deserialized
ConsumerRecord<K,V> consumerRecord = new ConsumerRecord<>(topic,data);

*) Internally data format is binary (byte[]) easy for trasfer and partitions

=> One consumer can read data from multiple topics too.
Ex:
@KafkaListener(topics = {
           "${my.topic.name2}",
	   "${my.topic.name1}",
	   "${my.topic.name3}"
         },
	groupId = "abcd")


*) Spring with Kafka uses MessagingMessageListenerAdapter(C)
 which is a Listener class that reads data from Kafka broker and
 converts data. 

*) Our application is connected with Kafka Server that runs on port : 9092
  Zookeeper runs on port: 2181 
=====================================================================
Gateway: Single entry and exit point for entire MS# apps.

=> Expose One IP/PORT
=> Single Entry and exit
=> Load Balancer
=> Connected with consumer apps (Angular/ReactJS/3rd Party)
=> Routing Table (Which request --> Where to Go)

 http://sampleapp.com/user/find/101
 http://sampleapp.com/cart/modify/106